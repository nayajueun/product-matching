{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import util, losses\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_file_dir = './data/computers_train/computers_train_large.json.gz'\n",
    "ft_valid_file_dir = './data/computers_valid/computers_valid_large.csv'\n",
    "n_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning bert model\n",
    "large_df = pd.read_json(fine_tuning_file_dir, compression='gzip', lines=True)\n",
    "large_df = large_df.drop(columns=['id_left', 'id_right', 'cluster_id_left', 'cluster_id_right', 'identifiers_left', 'identifiers_right'])\n",
    "valid_ids = pd.read_csv(ft_valid_file_dir)\n",
    "ft_train_df = large_df.loc[~large_df['pair_id'].isin(valid_ids['pair_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_json('./data/computers_train/computers_train_medium.json.gz', compression='gzip', lines=True)\n",
    "data_df = data_df.drop(columns=['id_left', 'id_right', 'cluster_id_left', 'cluster_id_right', 'identifiers_left', 'identifiers_right'])\n",
    "\n",
    "valid_ids = pd.read_csv('./data/computers_valid/computers_valid_medium.csv')\n",
    "\n",
    "train_df = data_df.loc[~data_df['pair_id'].isin(valid_ids['pair_id'])]\n",
    "valid_df = data_df.loc[data_df['pair_id'].isin(valid_ids['pair_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_similarity_vectorizer(value_left, value_right, vectorizer):\n",
    "    if value_left == None or value_right == None:\n",
    "        return None\n",
    "\n",
    "    if value_left == value_right:\n",
    "        return 1.0\n",
    "    tf_idf_left = vectorizer.transform([value_left])\n",
    "    tf_idf_right = vectorizer.transform([value_right])\n",
    "    sim = cosine_similarity(tf_idf_left, tf_idf_right)[0][0]\n",
    "    return sim\n",
    "\n",
    "\n",
    "def compute_features(df):\n",
    "    # TODO: title, brand and keyValue using Tfidf / encode all sentences at once to sbert\n",
    "    num_df = pd.DataFrame()\n",
    "    text_df = pd.concat([df['title_left'], df['title_right']])\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer = vectorizer.fit(text_df.values)\n",
    "    num_df['title_sim'] = df.apply(\n",
    "        lambda x: get_similarity_vectorizer(x['title_left'], x['title_right'], vectorizer), axis=1)\n",
    "    print(\"title done\")\n",
    "\n",
    "    text_df = pd.concat([df['description_left'], df['description_right']])\n",
    "    text_df = text_df.dropna(how=\"any\", axis=0)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer = vectorizer.fit(text_df.values)\n",
    "    num_df['description_sim'] = df.apply(\n",
    "        lambda x: get_similarity_vectorizer(x['description_left'], x['description_right'], vectorizer), axis=1)\n",
    "    print(\"descrition done\")\n",
    "\n",
    "    text_df = pd.concat([df['brand_left'], df['brand_right']])\n",
    "    text_df = text_df.dropna(how=\"any\", axis=0)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer = vectorizer.fit(text_df.values)\n",
    "    num_df['brand_sim'] = df.apply(lambda x: get_similarity_vectorizer(x['brand_left'], x['brand_right'], vectorizer), axis=1)\n",
    "    print(\"brand done\")\n",
    "\n",
    "    num_df['label'] = df['label']\n",
    "    return num_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title done\n",
      "descrition done\n",
      "brand done\n"
     ]
    }
   ],
   "source": [
    "num_train_df = compute_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title done\n",
      "descrition done\n",
      "brand done\n"
     ]
    }
   ],
   "source": [
    "num_valid_df = compute_features(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_sim</th>\n",
       "      <th>description_sim</th>\n",
       "      <th>brand_sim</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.574667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.586431</td>\n",
       "      <td>0.039588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.641244</td>\n",
       "      <td>0.140730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.662503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.212899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8089</th>\n",
       "      <td>0.144609</td>\n",
       "      <td>0.109454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8090</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8091</th>\n",
       "      <td>0.295581</td>\n",
       "      <td>0.361471</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8092</th>\n",
       "      <td>0.343734</td>\n",
       "      <td>0.207120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8093</th>\n",
       "      <td>0.304371</td>\n",
       "      <td>0.189632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6475 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      title_sim  description_sim  brand_sim  label\n",
       "3      0.574667              NaN        NaN      1\n",
       "4      0.586431         0.039588        1.0      1\n",
       "5      0.641244         0.140730        NaN      1\n",
       "6      0.662503              NaN        NaN      1\n",
       "7      0.212899              NaN        NaN      1\n",
       "...         ...              ...        ...    ...\n",
       "8089   0.144609         0.109454        0.0      0\n",
       "8090   0.000000         0.000000        0.0      0\n",
       "8091   0.295581         0.361471        1.0      0\n",
       "8092   0.343734         0.207120        1.0      0\n",
       "8093   0.304371         0.189632        1.0      0\n",
       "\n",
       "[6475 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "#isolate the x and y variables\n",
    "y_train = np.array(num_train_df['label'])\n",
    "X_train = num_train_df.drop(columns=[\"label\"])\n",
    "    \n",
    "y_test = np.array(num_valid_df['label'])\n",
    "X_test = num_valid_df.drop(columns=[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8094"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_train_df) + len(num_valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tYes-auc:0.87963\n",
      "[50]\tYes-auc:0.91091\n",
      "[100]\tYes-auc:0.91172\n",
      "[150]\tYes-auc:0.90917\n",
      "[199]\tYes-auc:0.90705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      1267\n",
      "           1       0.77      0.67      0.72       352\n",
      "\n",
      "    accuracy                           0.88      1619\n",
      "   macro avg       0.84      0.81      0.82      1619\n",
      "weighted avg       0.88      0.88      0.88      1619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#create xgboost matrices\n",
    "Train = xgb.DMatrix(X_train, label = y_train)\n",
    "Test = xgb.DMatrix(X_test, label = y_test)\n",
    "\n",
    "#set the parameters\n",
    "parameters = {'learning_rate': 0.3,\n",
    "               'max_depth': 2,\n",
    "               'colsample_bytree': 1,\n",
    "               'subsample': 1,\n",
    "               'min_child_weight': 1,\n",
    "               'gamma': 0, \n",
    "               'random_state': 1500,\n",
    "               'eval_metric': \"auc\",\n",
    "               'objective': \"binary:logistic\"}\n",
    "\n",
    "\n",
    "model = xgb.train(params = parameters,\n",
    "                dtrain = Train,\n",
    "                num_boost_round = 200,\n",
    "                evals = [(Test, \"Yes\")],\n",
    "                verbose_eval = 50)\n",
    "\n",
    "\n",
    "#PRedictions\n",
    "pred = model.predict(Test)\n",
    "pred = np.where(pred > 0.5, 1, 0)\n",
    "\n",
    "# confusion_matrix = confusion_matrix(y_test, pred)\n",
    "report = classification_report(y_test, pred)\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
